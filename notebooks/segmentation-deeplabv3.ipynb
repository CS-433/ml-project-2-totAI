{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbad72b3",
   "metadata": {},
   "source": [
    "Tous les imports dessous sont déjà dans le notebook principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccfc220",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T01:20:39.241042Z",
     "iopub.status.busy": "2024-12-12T01:20:39.240107Z",
     "iopub.status.idle": "2024-12-12T01:20:43.754779Z",
     "shell.execute_reply": "2024-12-12T01:20:43.753895Z"
    },
    "papermill": {
     "duration": 4.523507,
     "end_time": "2024-12-12T01:20:43.757622",
     "exception": false,
     "start_time": "2024-12-12T01:20:39.234115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = Path('../src').resolve()  \n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from helpers import get_loaders, metrics\n",
    "from plotting import visualize_results\n",
    "\n",
    "from DeepLabv3.deeplabv3plus import Deeplabv3Plus\n",
    "from DeepLabv3.dice_bce_loss import DiceBCELoss\n",
    "from DeepLabv3.iou import IOU\n",
    "from DeepLabv3.train_deeplab import train_deeplab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c227b",
   "metadata": {},
   "source": [
    "### Training `DeepLabv3` on processed data where we only keep the roofs on images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c70f8",
   "metadata": {},
   "source": [
    "We now want to compare another architecture named **DeepLabv3**, with UNet to leverage their different strengths. DeepLabv3 incorporates **atrous convolutions** for capturing multi-scale context and global context awareness. In the literature, it is known to be particularly good at **semantic segmentation** tasks.\n",
    "\n",
    "Here are the **parameters** used for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d35c4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T01:20:43.767536Z",
     "iopub.status.busy": "2024-12-12T01:20:43.767155Z",
     "iopub.status.idle": "2024-12-12T01:20:43.834867Z",
     "shell.execute_reply": "2024-12-12T01:20:43.833602Z"
    },
    "papermill": {
     "duration": 0.07572,
     "end_time": "2024-12-12T01:20:43.837420",
     "exception": false,
     "start_time": "2024-12-12T01:20:43.761700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "\n",
    "ROOT_DIR = \"../data/\"\n",
    "images_dir = os.path.join(ROOT_DIR, \"images/\")\n",
    "roof_images_dir = os.path.join(ROOT_DIR, \"roofs/images/\")\n",
    "labels_dir = os.path.join(ROOT_DIR, \"labels/\")\n",
    "weights_dir = os.path.join(ROOT_DIR, \"weights/\")\n",
    "\n",
    "image_names = [file for file in os.listdir(images_dir) if file.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23f405",
   "metadata": {},
   "source": [
    "Before loading the data, we need to **standardize** the images to ensure consistent input scaling for our Convolutional Neural Network (CNN). Standardization transforms the pixel values so that they have a **mean of 0** and a **standard deviation of 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4aede4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T01:20:43.864923Z",
     "iopub.status.busy": "2024-12-12T01:20:43.864621Z",
     "iopub.status.idle": "2024-12-12T01:20:44.159194Z",
     "shell.execute_reply": "2024-12-12T01:20:44.158465Z"
    },
    "papermill": {
     "duration": 0.30082,
     "end_time": "2024-12-12T01:20:44.161188",
     "exception": false,
     "start_time": "2024-12-12T01:20:43.860368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deeplab_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb4624",
   "metadata": {},
   "source": [
    "We can now load the data, using the same segmentation dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c19ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    image_names[:10],\n",
    "    images_dir,\n",
    "    labels_dir,\n",
    "    BATCH_SIZE,\n",
    "    deeplab_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c7a88",
   "metadata": {},
   "source": [
    "\n",
    "### Model, Loss, and Optimizer Setup\n",
    "\n",
    "- **Model**: Using the `DeepLabv3Plus` architecture for segmentation with a single output class.\n",
    "- **Loss Function**: `DiceBCELoss` to handle class imbalance and optimize segmentation performance.\n",
    "- **Evaluation Metric**: Intersection over Union (`IOU`) for measuring segmentation accuracy, used before.\n",
    "- **Mixed Precision**: `torch.amp.GradScaler` for efficient training on CUDA devices.\n",
    "- **Optimizer**: Adam optimizer with a specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f02eb9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T01:20:48.490446Z",
     "iopub.status.busy": "2024-12-12T01:20:48.490170Z",
     "iopub.status.idle": "2024-12-12T01:20:50.166312Z",
     "shell.execute_reply": "2024-12-12T01:20:50.165412Z"
    },
    "papermill": {
     "duration": 1.684409,
     "end_time": "2024-12-12T01:20:50.168475",
     "exception": false,
     "start_time": "2024-12-12T01:20:48.484066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ducou\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ducou\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = Deeplabv3Plus(num_classes=1).to(DEVICE)\n",
    "loss_fn = DiceBCELoss()\n",
    "iou_fn = IOU()\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a890f3",
   "metadata": {},
   "source": [
    "We can now train the **DeepLabv3+ model** on the initial images (i.e with no magenta), using the parameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71ee9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T01:20:50.186466Z",
     "iopub.status.busy": "2024-12-12T01:20:50.185679Z",
     "iopub.status.idle": "2024-12-12T05:34:49.823717Z",
     "shell.execute_reply": "2024-12-12T05:34:49.822598Z"
    },
    "papermill": {
     "duration": 15239.648357,
     "end_time": "2024-12-12T05:34:49.825860",
     "exception": false,
     "start_time": "2024-12-12T01:20:50.177503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\ducou\\OneDrive\\Bureau\\Cours EPFL\\MA1\\Machine Learning\\swiss-solar-panel-segmentation\\src\\segmentation_dataset.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image, mask = torch.tensor(transformed[\"image\"]), torch.Tensor(\n",
      "Training Epoch 1: 100%|██████████| 4/4 [01:53<00:00, 28.26s/it, diceloss=1.59, iou=1.15e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Training loss: 1.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1000, 1000]) torch.Size([1, 1, 1000, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1: 100%|██████████| 1/1 [00:04<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0040, 0.0041, 0.0042,  ..., 0.6682, 0.6701, 0.6845])\n",
      "Got 987064/1000000 with acc 98.71%\n",
      "Dice score: 0.0136\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_iou = train_deeplab(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    iou_fn=iou_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    scaler=scaler,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6263587,
     "sourceId": 10146956,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "sdsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15600.577048,
   "end_time": "2024-12-12T05:40:37.350887",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-12T01:20:36.773839",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
